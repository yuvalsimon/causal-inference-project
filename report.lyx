#LyX 2.3 created this file. For more info see http://www.lyx.org/
\lyxformat 544
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass article
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures true
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry false
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\use_minted 0
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\is_math_indent 0
\math_numbering_side default
\quotes_style english
\dynamic_quotes 0
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
Online Article's Popularity
\end_layout

\begin_layout Author
Yuval Simon
\begin_inset Newline newline
\end_inset

Ifat Peczenik
\end_layout

\begin_layout Section
Introduction
\end_layout

\begin_layout Standard
Digital content consumption has grown rapidly over the years as people are
 spending more and more time reading online content.
 Together with the growing number of users, also the competition between
 online media platforms has rapidly increased.
 Online media platforms like Medium, Mashable and Buzzfeed publish hundreds
 of articles every day, aiming to bring the best content to the users and
 bring most shares.
 
\end_layout

\begin_layout Standard
Article's popularity can be estimated by its number of shares.
 In this project we will try to estimate the causal effect of publishing
 an article during weekend on its popularity, which is measured by its number
 of shares.
 There are some confounders that can affect the popularity of an article
 and we take them into account in our estimations, for example some readers
 might not have time to read a very long article, or the title of an article
 might be less distracting even though the article is great.
 Many confounders are hidden, but we'll try to disable some of them where
 it is possible.
\end_layout

\begin_layout Section
Data
\end_layout

\begin_layout Standard
Our data contains around 39000 articles that were published in Mashable
 between 07/01/2013 and 27/12/2014.
 
\end_layout

\begin_layout Standard
For each article the data contains many features that could have also been
 extracted from the article's url, for instance:
\end_layout

\begin_layout Itemize
Publish date
\end_layout

\begin_layout Itemize
Data channel: business, entertainment, social media, world, technology,
 lifestyle
\end_layout

\begin_layout Itemize
Number of images, videos, links
\end_layout

\begin_layout Itemize
Article's length: number of words in the title/content
\end_layout

\begin_layout Itemize
Number of keywords
\end_layout

\begin_layout Itemize
Rate of positive and negative words
\end_layout

\begin_layout Itemize
Title and content subjectivity level 
\end_layout

\begin_layout Itemize
Max, min and average polarity of positive and negative word
\end_layout

\begin_layout Itemize
Published on weekend or not 
\end_layout

\begin_layout Itemize
Number of shares
\end_layout

\begin_layout Standard
Some features in the dataset, like word polarity and subjectivity level,
 are features that were calculated with some method unknown to us.
 We take it as-is and we assume the dataset author exploited good methods
 to calculate them.
\end_layout

\begin_layout Standard
In addition there are some hidden confounders we need to address:
\end_layout

\begin_layout Itemize
Audience - we don't know the characteristics of people that enter to the
 website, and specifically to each of the channels in Mashable.
\end_layout

\begin_layout Itemize
Promotion algorithms - some articles are promoted at main view of Mashable.
 In 2013-2014 there were 3 promotion areas - 
\begin_inset Quotes eld
\end_inset

The New Stuff
\begin_inset Quotes erd
\end_inset

, 
\begin_inset Quotes eld
\end_inset

The Next Big Thing
\begin_inset Quotes erd
\end_inset

 and 
\begin_inset Quotes eld
\end_inset

What's Hot
\begin_inset Quotes erd
\end_inset

.
 We don't know which articles were promoted and how much could increase
 the chances of an article to get shared more.
\end_layout

\begin_layout Itemize
Advertising - some articles might had been advertised in other websites,
 like Facebook and Google.
\end_layout

\begin_layout Itemize
Special occasions - some articles might had been published after some special
 occasion.
 For example, an article about Apple that is published after Apple reveals
 its new Iphone may get more exposure.
\end_layout

\begin_layout Standard
\begin_inset CommandInset href
LatexCommand href
target "https://www.kaggle.com/srikaranelakurthy/online-news-popularity"

\end_inset


\end_layout

\begin_layout Subsection
Data assumptions to estimate causal effect
\end_layout

\begin_layout Enumerate
Stable unit treatment value assumption (SUTVA)- potential outcomes for any
 unit do not vary with the treatments assigned to other units.
 In our dataset, number of shares that one article received doesn't impact
 number of shares that other articles are getting.
 Moreover, for every article, there are no different forms of versions of
 each treatment level.
 Every article is published on weekday (treatment T=0) or weekend (treatment
 T=1).
\end_layout

\begin_layout Enumerate
Consistency- for a unit that receives treatment T, we observe the corresponding
 potential outcome Yt.
 Here we have published day for every article as well as number of shares
 it got.
 
\end_layout

\begin_layout Enumerate
Common support (overlap)- we assume that every unit in our dataset has probabili
ty greater than 0 to get T=0 or T=1.
 Plot histogram of propensity scores: 
\end_layout

\begin_layout Enumerate
Ignorability- no unmeasured confounders.
 In other words, two observations with the same set of covariates X but
 with different treatment assignments can be compared to estimate the causal
 effect of the treatment for these observations.
 Here we assume that in our dataset all hidden confounders that affect the
 treatment have no effect on the outcome Y (number of shares), except through
 T (published in weekday or weekend), although this assumption is unverifiable
 from the data itself.
 
\end_layout

\begin_layout Subsection*
Correlation between features:
\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename https:/raw.githubusercontent.com/yuvalsimon/causal-inference-project/main/images/corr_matrix.png

\end_inset


\end_layout

\begin_layout Subsection*
Logistic Regression feature importance:
\end_layout

\begin_layout Section
Methods
\end_layout

\begin_layout Section
Results
\end_layout

\begin_layout Section
Weaknesses
\end_layout

\begin_layout Itemize
In our dataset there are only 5190 articles published on weekend (T=1) comparing
 to 34000 articles from weekdays (T=0).
 Ideally we would want to have equal number of units with T=0 and T=1, this
 will increase confidence in our causal analysis.
 Having more articles from weekends could potentially change our results
 and impact final conclusions.
 
\end_layout

\begin_layout Itemize
We may have hidden confounders that are impacting only outcome Y, number
 of shares.
 We assumed that all hidden confounders are impacting Y only through T and
 by that our data is having ignorability.
 However, this asssumption can't be verifiable from the data itself.
\end_layout

\begin_layout Itemize
Original dataset contains 60 different features for every article.
 Since we have relatively small number of records, we had to remove some
 of those features (possible confounders).
 
\end_layout

\begin_layout Section
Discussion
\end_layout

\end_body
\end_document
